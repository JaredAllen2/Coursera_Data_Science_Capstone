---
title: "n-gram prediction model"
author: "Jared Allen"
date: "08/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidytext)
library(stringr)
library(knitr)
library(ngram)
library(tm)
library(data.table)
```

```{r data_import, warning=FALSE, echo=TRUE}

con<- file("Data/final/en_US/en_US.twitter.txt","r")
en_us_twitter <- readLines(con)
en_us_twitter <- tibble(en_us_twitter)
close(con)

con<- file("Data/final/en_US/en_US.blogs.txt","r")
en_us_blogs <- readLines(con)
en_us_blogs <- tibble(en_us_blogs)
close(con)

con<- file("Data/final/en_US/en_US.news.txt","r")
en_us_news <- readLines(con)
en_us_news <- tibble(en_us_news)
close(con)
```

```{r data_subset}
sampleprop = 0.5

set.seed(061119)
en_us_blog_subset <- data.table(data=sample(en_us_blogs$en_us_blogs,(ceiling(nrow(en_us_blogs)*sampleprop))),stringsAsFactors = FALSE)
en_us_news_subset <- data.table(data=sample(en_us_news$en_us_news,(ceiling(nrow(en_us_news)*sampleprop))),stringsAsFactors = FALSE)
en_us_twitter_subset <- data.table(data=sample(en_us_twitter$en_us_twitter,(ceiling(nrow(en_us_twitter)*sampleprop))),stringsAsFactors = FALSE)

en_us_capstone_subset <- 
  data.frame(en_us_blog_subset) %>%
  mutate(source=as.character("blog")) %>%
  bind_rows(data.frame(en_us_news_subset)) %>%
  mutate(source=ifelse(is.na(source),as.character("news"),source)) %>%
  bind_rows(data.frame(en_us_twitter_subset)) %>%
  mutate(source=ifelse(is.na(source),as.character("twitter"),source))
  
```

```{r dataset cleaning}

tidy_en_us_capstone_subset <- en_us_capstone_subset

tidy_en_us_capstone_subset <-
  unnest_tokens(tidy_en_us_capstone_subset,data,data,token="lines",format="text") %>%
  mutate(data=iconv(tidy_en_us_capstone_subset$data,"latin1","ASCII",sub="")) %>%
  mutate(data=str_replace_all(tidy_en_us_capstone_subset$data, "[^a-zA-Z ]", "")) %>%
  mutate(data=str_trim(data, "both")) %>%
  filter(data!="") %>%
  drop_na(data)

```

```{r restructure_ngrams}
en_us_capstone_subset_tidy_unigrams <-
  tidy_en_us_capstone_subset %>%
  unnest_tokens(word1,data,token = "ngrams",n=1, collapse=FALSE) %>%
  drop_na(word1)

en_us_capstone_subset_tidy_bigrams <-
  tidy_en_us_capstone_subset %>%
  unnest_tokens(bigram,data,token = "ngrams",n=2, collapse=FALSE) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  drop_na(word1)

en_us_capstone_subset_tidy_trigrams <-
  tidy_en_us_capstone_subset %>%
  unnest_tokens(trigram,data,token = "ngrams",n=3, collapse=FALSE) %>%
  separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
  drop_na(word1)

en_us_capstone_subset_tidy_quadgrams <-
  tidy_en_us_capstone_subset %>%
  unnest_tokens(quadgram,data,token = "ngrams",n=4, collapse=FALSE) %>%
  separate(quadgram, c("word1", "word2", "word3", "word4"), sep = " ") %>%
  drop_na(word1)

```

```{r ngram_frequency}

en_us_capstone_subset_tidy_unigrams_freq <-
  en_us_capstone_subset_tidy_unigrams %>%
  count(word1) %>%
  filter(n>1) %>%
  mutate(relfreq = n / sum(n)) %>%
  arrange(desc(relfreq)) %>%
  mutate(cumfreq=cumsum(relfreq))

en_us_capstone_subset_tidy_bigrams_freq <-
  en_us_capstone_subset_tidy_bigrams %>%
  count(word1,word2) %>%
  filter(n>1) %>%
  mutate(relfreq = n / sum(n)) %>%
  arrange(desc(relfreq)) %>%
  mutate(cumfreq=cumsum(relfreq))

en_us_capstone_subset_tidy_trigrams_freq <-
  en_us_capstone_subset_tidy_trigrams %>%
  count(word1,word2,word3) %>%
  filter(n>1) %>%
  mutate(relfreq = n / sum(n)) %>%
  arrange(desc(relfreq)) %>%
  mutate(cumfreq=cumsum(relfreq))

en_us_capstone_subset_tidy_quadgrams_freq <-
  en_us_capstone_subset_tidy_quadgrams %>%
  count(word1,word2,word3,word4) %>%
  filter(n>1) %>%
  mutate(relfreq = n / sum(n)) %>%
  arrange(desc(relfreq)) %>%
  mutate(cumfreq=cumsum(relfreq))

```


```{r ngram_rel}

# for each n-gram reference set, remove all but the top 3

tidy_unigrams <-
  en_us_capstone_subset_tidy_unigrams %>%
  count(word1) %>%
  mutate(relfreq = n / sum(n)) %>%
  mutate(topword=min_rank(desc(n))) %>%
  arrange(desc(relfreq)) %>%
  mutate(relfreq = n / sum(n))

tidy_bigrams <-
  en_us_capstone_subset_tidy_bigrams %>%
  count(word1,word2) %>%
  filter(n>1) %>%
  arrange(word1,desc(n)) %>%
  group_by(word1) %>%
  mutate(topword=min_rank(desc(n))) %>%
  mutate(relfreq = n / sum(n)) %>%
  filter(topword<=3)

tidy_trigrams <-
  en_us_capstone_subset_tidy_trigrams %>%
  count(word1,word2,word3) %>%
  filter(n>1) %>%
  arrange(word1,word2,desc(n)) %>%
  group_by(word1,word2) %>%
  mutate(topword=min_rank(desc(n))) %>%
  mutate(relfreq = n / sum(n)) %>%
  filter(topword<=3)

tidy_quadgrams <-
  en_us_capstone_subset_tidy_quadgrams %>%
  count(word1,word2,word3,word4) %>%
  filter(n>1) %>%
  arrange(word1,word2,word3,desc(n)) %>%
  group_by(word1,word2,word3) %>%
  mutate(topword=min_rank(desc(n))) %>%
  mutate(relfreq = n / sum(n)) %>%
  filter(topword<=3)


```

```{r katzbackoff_functions}

# for a given word, predict the next using the bigram data
wordpredictn1 <- function(word_1) {
  tidy_bigrams %>%
    filter(word1==word_1)
}

wordpredictn2 <- function(word_1,word_2) {
  tidy_trigrams %>%
    filter(word1==word_1 & word2==word_2)
}

wordpredictn3 <- function(word_1,word_2,word_3) {
  tidy_quadgrams %>%
    filter(word1==word_1 & word2==word_2 & word3==word_3)
}

wordpredict <- function(input) {
  
  wordsin <- str_split(input,"[[:punct:] ]+",simplify=TRUE)  
  stringlength <- length(wordsin)

  if (stringlength >=3) {
    suggestedwords <- wordpredictn3(wordsin[stringlength-2],wordsin[stringlength-1],wordsin[stringlength])
    
    
  } else if (stringlength >= 2) {
    suggestedwords <- wordpredictn2(wordsin[stringlength-1],wordsin[stringlength])
    

  } else if (stringlength >= 1) {
    suggestedwords <- wordpredictn1(wordsin[stringlength])

  }
  suggestedwords
}

```