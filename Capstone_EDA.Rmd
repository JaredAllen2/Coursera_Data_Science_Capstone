---
title: "Capstone EDA"
author: "Jared Allen"
date: "30/09/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidytext)
library(stringr)
library(tm)
library(quanteda)
```

## Introduction
The first step in building a predictive model for text is understanding the distribution and relationship between the words, tokens, and phrases in the text. The goal of this task is to understand the basic relationships you observe in the data and prepare to build your first linguistic models.

Tasks to accomplish

Exploratory analysis - perform a thorough exploratory analysis of the data, understanding the distribution of words and relationship between the words in the corpora.

Understand frequencies of words and word pairs - build figures and tables to understand variation in the frequencies of words and word pairs in the data.

## Data Import

Data import has been accomplished through the use of the readLines function in R, storing the data in tibble format to adhere to tidy data principles.

```{r data_import, warning=FALSE, echo=TRUE}

con<- file("Data/final/en_US/en_US.twitter.txt","r")
en_us_twitter <- readLines(con)
en_us_twitter <- tibble(en_us_twitter)
close(con)

con<- file("Data/final/en_US/en_US.blogs.txt","r")
en_us_blogs <- readLines(con)
en_us_blogs <- tibble(en_us_blogs)
close(con)

con<- file("Data/final/en_US/en_US.news.txt","r")
en_us_news <- readLines(con)
en_us_news <- tibble(en_us_news)
close(con)
```

```{r data_summary}
summary(en_us_twitter)
summary(en_us_blogs)
summary(en_us_news)

```

The dataset consists of three files containing the following:

```{r restructure_trigrams}
en_us_twitter_tidy_unigrams <-
  en_us_twitter %>%
  unnest_tokens(unigram,en_us_twitter,token = "ngrams",n=1)

en_us_twitter_tidy_bigrams <-
  en_us_twitter %>%
  unnest_tokens(bigram,en_us_twitter,token = "ngrams",n=2)

en_us_twitter_tidy_trigrams <-
  en_us_twitter %>%
  unnest_tokens(trigram,en_us_twitter,token = "ngrams",n=3)

```

```{r counts}
en_us_twitter_tidy_unigrams %>%
  count(unigram,sort=TRUE)

en_us_twitter_tidy_bigrams %>%
  count(bigram,sort=TRUE)

en_us_twitter_tidy_trigrams %>%
  count(trigram,sort=TRUE)

```

