---
title: "n-gram improvements"
author: "Jared Allen"
date: "11/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidytext)
library(stringr)
library(knitr)
library(ngram)
library(tm)
library(data.table)
```

```{r data_import, warning=FALSE, echo=TRUE}

con<- file("Data/final/en_US/en_US.twitter.txt","r")
en_us_twitter <- readLines(con)
en_us_twitter <- data.table(en_us_twitter)
close(con)

con<- file("Data/final/en_US/en_US.blogs.txt","r")
en_us_blogs <- readLines(con)
en_us_blogs <- data.table(en_us_blogs)
close(con)

con<- file("Data/final/en_US/en_US.news.txt","r")
en_us_news <- readLines(con)
en_us_news <- data.table(en_us_news)
close(con)
```

```{r data_subset_dt}

setnames(en_us_blogs,"en_us_blogs","data",skip_absent=TRUE)
en_us_blogs <- en_us_blogs[,data:=iconv(data,"latin1","ASCII",sub="")][,data:=str_replace_all(data, "[^a-zA-Z ]", "")][,data:=str_trim(data, "both")][data!=""][!is.na(data)][lengths(strsplit(data," "))>1]

setnames(en_us_news,"en_us_news","data",skip_absent=TRUE)
en_us_news <- en_us_news[,data:=iconv(data,"latin1","ASCII",sub="")][,data:=str_replace_all(data, "[^a-zA-Z ]", "")][,data:=str_trim(data, "both")][data!=""][!is.na(data)][lengths(strsplit(data," "))>1]

setnames(en_us_twitter,"en_us_twitter","data",skip_absent=TRUE)
en_us_twitter <- en_us_twitter[,data:=iconv(data,"latin1","ASCII",sub="")][,data:=str_replace_all(data, "[^a-zA-Z ]", "")][,data:=str_trim(data, "both")][data!=""][!is.na(data)][lengths(strsplit(data," "))>1]

capstone <- rbindlist(list(en_us_blogs,en_us_news,en_us_twitter),use.names=TRUE, idcol=TRUE)
setkey(capstone,data)

rm(en_us_blogs,en_us_news,en_us_twitter)
```

```{r capstone cleaning}
profanewords <- readLines("https://raw.githubusercontent.com/shutterstock/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/master/en")
close(con)

#remove all lines from capstone dataset which contain a profane word
capstone <- capstone[!grepl(paste(profanewords, collapse=" | "),data,ignore.case = TRUE)]

rm(profanewords)
```

```{r restructure_unigrams}
capstone_unigrams <- unnest_tokens(capstone,word1,data,token = "ngrams",n=1, collapse=FALSE)
```

```{r unigram_freq}
unigrams <- capstone_unigrams[!is.na(word1)][,.N,by=word1][N>1] #[,relfreq:=N/sum(N)][order(-N)][,topword:=min_rank(desc(N))][topword<=3]
rm(capstone_unigrams)
```

```{r restructure_bigrams}
capstone_bigrams <- unnest_tokens(capstone,bigram,data,token = "ngrams",n=2, collapse=FALSE)
capstone_bigrams <- separate(capstone_bigrams,bigram, c("word1", "word2"), sep = " ")
```

```{r bigram_freq}
bigrams <- capstone_bigrams[!is.na(word1)][,.N,by=.(word1,word2)][N>1] #[,relfreq:=N/sum(N),by=word1][order(word1,-N)][,topword:=min_rank(desc(N)),by=word1][topword<=3]
rm(capstone_bigrams)
```

```{r restructure_trigrams}
capstone_trigrams <- unnest_tokens(capstone,trigram,data,token = "ngrams",n=3, collapse=FALSE)
capstone_trigrams <- separate(capstone_trigrams,trigram, c("word1", "word2","word3"), sep = " ")
```

```{r trigram_freq}
trigrams <- capstone_trigrams[!is.na(word1)][,.N,by=.(word1,word2,word3)][N>1] #[,relfreq:=N/sum(N),by=.(word1,word2)][order(word1,word2,-N)][,topword:=min_rank(desc(N)),by=.(word1,word2)][topword<=3]
rm(capstone_trigrams)
```

```{r restructure_quadgrams}
capstone_quadgrams <- unnest_tokens(capstone,quadgram,data,token = "ngrams",n=4, collapse=FALSE)
capstone_quadgrams <- separate(capstone_quadgrams,quadgram, c("word1", "word2","word3","word4"), sep = " ")
```

```{r quadgram_freq}
quadgrams <- capstone_quadgrams[!is.na(word1)][,.N,by=.(word1,word2,word3,word4)][N>1] #[,relfreq:=N/sum(N),by=.(word1,word2,word3)][order(word1,word2,word3,-N)][,topword:=min_rank(desc(N)),by=.(word1,word2,word3)][topword<=3]
rm(capstone_quadgrams)
```

```{r katzbackoff_functions}

# for a given word, predict the next using the bigram data
wordpredictn1 <- function(word_1) {
  bigrams[word1==word_1][order(-N)]
}

wordpredictn2 <- function(word_1,word_2) {
  trigrams[word1==word_1 & word2==word_2][order(word1,-N)]
}

wordpredictn3 <- function(word_1,word_2,word_3) {
  quadgrams[word1==word_1 & word2==word_2 & word3==word_3][order(word1,word2,-N)]
}

wordpredict <- function(input) {
  
  wordsin <- str_split(input,"[[:punct:] ]+",simplify=TRUE)  
  stringlength <- length(wordsin)

  if (stringlength >=3) {
    suggestedwords <- wordpredictn3(wordsin[stringlength-2],wordsin[stringlength-1],wordsin[stringlength])

    
  } else if (stringlength == 2) {
    suggestedwords <- wordpredictn2(wordsin[stringlength-1],wordsin[stringlength])
    

  } else if (stringlength == 1) {
    suggestedwords <- wordpredictn1(wordsin[stringlength])

  }
  suggestedwords
}

```