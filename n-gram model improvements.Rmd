---
title: "n-gram improvements"
author: "Jared Allen"
date: "11/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidytext)
library(stringr)
library(knitr)
library(ngram)
library(tm)
```

```{r data_import, warning=FALSE, echo=TRUE}

con<- file("Data/final/en_US/en_US.twitter.txt","r")
en_us_twitter <- readLines(con)
en_us_twitter <- tibble(en_us_twitter)
close(con)

con<- file("Data/final/en_US/en_US.blogs.txt","r")
en_us_blogs <- readLines(con)
en_us_blogs <- tibble(en_us_blogs)
close(con)

con<- file("Data/final/en_US/en_US.news.txt","r")
en_us_news <- readLines(con)
en_us_news <- tibble(en_us_news)
close(con)
```

```{r data_subset}

tidy_blog <-
  en_us_blogs %>%
  rename(data=en_us_blogs) %>%
  unnest_tokens(data,data,token="lines",format="text") %>%
  mutate(data=iconv(data,"latin1","ASCII",sub="")) %>%
  mutate(data=str_replace_all(data, "[^a-zA-Z ]", "")) %>%
  mutate(data=str_trim(data, "both")) %>%
  filter(data!="") %>%
  filter(lengths(strsplit(data," "))>10) %>%
  drop_na(data)
rm(en_us_blogs)

tidy_news <-
  en_us_news %>%
  rename(data=en_us_news) %>%
  unnest_tokens(data,data,token="lines",format="text") %>%
  mutate(data=iconv(data,"latin1","ASCII",sub="")) %>%
  mutate(data=str_replace_all(data, "[^a-zA-Z ]", "")) %>%
  mutate(data=str_trim(data, "both")) %>%
  filter(data!="") %>%
  filter(lengths(strsplit(data," "))>10) %>%
  drop_na(data)
rm(en_us_news)

tidy_twitter <-
  en_us_twitter %>%
  rename(data=en_us_twitter) %>%
  unnest_tokens(data,data,token="lines",format="text") %>%
  mutate(data=iconv(data,"latin1","ASCII",sub="")) %>%
  mutate(data=str_replace_all(data, "[^a-zA-Z ]", "")) %>%
  mutate(data=str_trim(data, "both")) %>%
  filter(data!="") %>%
  filter(lengths(strsplit(data," "))>10) %>%
  drop_na(data)
rm(en_us_twitter)

capstone <- 
   tidy_blog %>%
   mutate(source=as.character("blog")) %>%
   bind_rows(tidy_news) %>%
   mutate(source=ifelse(is.na(source),as.character("news"),source)) %>%
   bind_rows(tidy_twitter) %>%
   mutate(source=ifelse(is.na(source),as.character("twitter"),source))
rm(tidy_blog,tidy_news,tidy_twitter)  

```

```{r restructure_ngrams}
capstone_unigrams <-
  capstone %>%
  unnest_tokens(word1,data,token = "ngrams",n=1, collapse=FALSE) %>%
  drop_na(word1)

capstone_bigrams <-
  capstone %>%
  unnest_tokens(bigram,data,token = "ngrams",n=2, collapse=FALSE) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  drop_na(word1)

capstone_trigrams <-
  capstone %>%
  unnest_tokens(trigram,data,token = "ngrams",n=3, collapse=FALSE) %>%
  separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
  drop_na(word1)

capstone_quadgrams <-
  capstone %>%
  unnest_tokens(quadgram,data,token = "ngrams",n=4, collapse=FALSE) %>%
  separate(quadgram, c("word1", "word2", "word3", "word4"), sep = " ") %>%
  drop_na(word1)

```

```{r ngram_frequency}
# 
# capstone_unigrams_freq <-
#   capstone_unigrams %>%
#   count(word1) %>%
#   filter(n>1) %>%
#   mutate(relfreq = n / sum(n)) %>%
#   arrange(desc(relfreq)) %>%
#   mutate(cumfreq=cumsum(relfreq))
# #rm(capstone_unigrams)
# 
# capstone_bigrams_freq <-
#   capstone_bigrams %>%
#   count(word1,word2) %>%
#   filter(n>1) %>%
#   mutate(relfreq = n / sum(n)) %>%
#   arrange(desc(relfreq)) %>%
#   mutate(cumfreq=cumsum(relfreq))
# # #rm(capstone_bigrams)
# # 
# capstone_trigrams_freq <-
#   capstone_trigrams %>%
#   count(word1,word2,word3) %>%
#   filter(n>1) %>%
#   mutate(relfreq = n / sum(n)) %>%
#   arrange(desc(relfreq)) %>%
#   mutate(cumfreq=cumsum(relfreq))
# # #rm(capstone_trigrams)
# # 
# capstone_quadgrams_freq <-
#   capstone_quadgrams %>%
#   count(word1,word2,word3,word4) %>%
#   filter(n>1) %>%
#   mutate(relfreq = n / sum(n)) %>%
#   arrange(desc(relfreq)) %>%
#   mutate(cumfreq=cumsum(relfreq))
# # #rm(capstone_quadgrams)

```


```{r ngram_rel}

# for each n-gram reference set, remove all but the top 3

tidy_unigrams <-
  capstone_unigrams %>%
  count(word1) %>%
  mutate(relfreq = n / sum(n)) %>%
  mutate(topword=min_rank(desc(n))) %>%
  arrange(desc(relfreq)) %>%
  mutate(relfreq = n / sum(n))
rm(capstone_unigrams_freq)

tidy_bigrams <-
  capstone_bigrams_freq %>%
  count(word1,word2) %>%
  filter(n>1) %>%
  arrange(word1,desc(n)) %>%
  group_by(word1) %>%
  mutate(topword=min_rank(desc(n))) %>%
  mutate(relfreq = n / sum(n)) %>%
  filter(topword<=3)
rm(capstone_bigrams_freq)

tidy_trigrams <-
  capstone_trigrams_freq %>%
  count(word1,word2,word3) %>%
  filter(n>1) %>%
  arrange(word1,word2,desc(n)) %>%
  group_by(word1,word2) %>%
  mutate(topword=min_rank(desc(n))) %>%
  mutate(relfreq = n / sum(n)) %>%
  filter(topword<=3)
rm(capstone_trigrams_freq)

tidy_quadgrams <-
  capstone_quadgrams_freq %>%
  count(word1,word2,word3,word4) %>%
  filter(n>1) %>%
  arrange(word1,word2,word3,desc(n)) %>%
  group_by(word1,word2,word3) %>%
  mutate(topword=min_rank(desc(n))) %>%
  mutate(relfreq = n / sum(n)) %>%
  filter(topword<=3)
rm(capstone_quadgrams_freq)


```

```{r katzbackoff_functions}

# for a given word, predict the next using the bigram data
wordpredictn1 <- function(word_1) {
  tidy_bigrams %>%
    filter(word1==word_1)
}

wordpredictn2 <- function(word_1,word_2) {
  tidy_trigrams %>%
    filter(word1==word_1 & word2==word_2)
}

wordpredictn3 <- function(word_1,word_2,word_3) {
  tidy_quadgrams %>%
    filter(word1==word_1 & word2==word_2 & word3==word_3)
}

wordpredict <- function(input) {
  
  wordsin <- str_split(input,"[[:punct:] ]+",simplify=TRUE)  
  stringlength <- length(wordsin)

  if (stringlength >=3) {
    suggestedwords <- wordpredictn3(wordsin[stringlength-2],wordsin[stringlength-1],wordsin[stringlength])

    
  } else if (stringlength == 2) {
    suggestedwords <- wordpredictn2(wordsin[stringlength-1],wordsin[stringlength])
    

  } else if (stringlength == 1) {
    suggestedwords <- wordpredictn1(wordsin[stringlength])

  }
  suggestedwords
}

```